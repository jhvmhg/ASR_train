{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import jieba\n",
    "from lib.io import parse_file_to_dict, write_dict_to_file, get_new_id, copy_file_if_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd data && python ../tools/prep_dict.py lexicon.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./tools/prepare_dict.sh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf gmm/data/dict/\n",
    "# !mkdir gmm/data/dict/\n",
    "# !cd data &&cp lexicon.txt silence_phones.txt nonsilence_phones.txt extra_questions.txt optional_silence.txt ../gmm/data/dict\n",
    "# # !rm silence_phones.txt nonsilence_phones.txt extra_questions.txt optional_silence.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16k生成wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_16k = \"/home1/meichaoyang/Dataset/16k\"\n",
    "wav_list_16k=list(Path(dir_16k).rglob(\"*.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_raw_16k = \"/home1/meichaoyang/Dataset/16k/usort-c.txt\"\n",
    "corp_map_16k = {}\n",
    "with open(corp_raw_16k, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        corp_map_16k[data[0].split(\"/\")[-1].split(\".\")[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_list_16k.sort(key=lambda Path: os.path.basename(os.path.splitext((str(Path)))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_16k = {}\n",
    "for path_item in wav_list_16k:\n",
    "    wav_path = str(path_item)\n",
    "    scp_16k[os.path.basename(os.path.splitext((wav_path))[0])] = wav_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/16k_wav.scp', 'w') as f:\n",
    "    for i in sorted(scp_16k):\n",
    "        if i in corp_map_16k:\n",
    "            f.write(i+'\\t'+scp_16k[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/16k_trans.txt', 'w') as f:\n",
    "    for i in sorted(corp_map_16k):\n",
    "        if i in scp_16k:\n",
    "            f.write(i+'\\t'+corp_map_16k[i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aishell2数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成Aishell2的原始wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_dir = \"/home1/meichaoyang/Dataset/data_aishell2/data_aishell/wav/train\"\n",
    "aishell_wav_list=list(Path(aishell_dir).rglob(\"*.wav\"))\n",
    "aishell_wav_list.sort(key=lambda Path: os.path.basename(os.path.splitext((str(Path)))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_scp_raw = {}\n",
    "with open('tmp/Aishell_wav_raw.scp', 'w') as f:\n",
    "    for path_item in aishell_wav_list:\n",
    "        wav_path = str(path_item)\n",
    "        aishell_scp_raw[os.path.basename(os.path.splitext((wav_path))[0])] = wav_path\n",
    "        f.write(os.path.basename(os.path.splitext((wav_path))[0])+'\\t'+wav_path+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_2_corp_raw = \"/home1/meichaoyang/Dataset/data_aishell2/data_aishell/wav/trans.txt\"\n",
    "pattern_Eng = re.compile(u'[a-zA-Z\\n]')\n",
    "corp_map = {}\n",
    "with open(aishell_2_corp_raw, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        if pattern_Eng.search(data[1]) != None: ##删除小于10和非英文标注\n",
    "            continue\n",
    "        corp_map[data[0].split(\"/\")[-1].split(\".\")[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_scp = {}\n",
    "for i in sorted(aishell_scp_raw):\n",
    "    if i not in corp_map.keys():\n",
    "        continue\n",
    "    aishell_scp[i] = aishell_scp_raw[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/aishell_2.scp', 'w') as f:\n",
    "    for i in sorted(aishell_scp):\n",
    "        if i in corp_map:\n",
    "            f.write(i+'\\t'+aishell_scp[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/aishell_2_trans.txt', 'w') as f:\n",
    "    for i in sorted(corp_map):\n",
    "        if i in aishell_scp:\n",
    "            f.write(i+'\\t'+corp_map[i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_scp_16k = {}\n",
    "with open(\"tmp/16k_wav.scp\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        wav_scp_16k[data[0]] = data[1]\n",
    "        \n",
    "wav_corp_16k = {}      \n",
    "with open(\"tmp/16k_trans.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        if data[0] in wav_scp_16k:\n",
    "            wav_corp_16k[data[0]] = \"\".join(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_wav_scp = parse_file_to_dict(\"tmp/aishell_2.scp\")        \n",
    "aishell_wav_corp = parse_file_to_dict(\"tmp/aishell_2_trans.txt\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_scp = {**wav_scp_16k,**aishell_wav_scp}\n",
    "corpus = {**wav_corp_16k, **aishell_wav_corp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2384349 2384349\n"
     ]
    }
   ],
   "source": [
    "print(len(wav_scp),len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wav.scp', 'w') as f:\n",
    "    for i in sorted(wav_scp):\n",
    "        f.write(i+'\\t'+wav_scp[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/text', 'w') as f:\n",
    "    for i in sorted(corpus):\n",
    "        f.write(i+'\\t'+corpus[i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成词典并分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python tools/filter_scp.py corpus.seg wav.scp wav.scp.new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utt2spk和spk2utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wav_scp = parse_file_to_dict(\"data/wav.scp\",assert2fields=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utts = list(new_wav_scp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt2spk = {}\n",
    "for utt in utts:\n",
    "    if utt.startswith(\"A\"):\n",
    "        spk = utt\n",
    "    else:\n",
    "        spk = utt.split(\"W\")[0]\n",
    "    utt2spk[utt] = spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk2utt = {}\n",
    "for utt in utt2spk:\n",
    "    spk = utt2spk[utt]\n",
    "    if spk not in spk2utt:\n",
    "        spk2utt[spk] = []\n",
    "    spk2utt[spk].append(utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/utt2spk', 'w') as f:\n",
    "    for i in sorted(utt2spk):\n",
    "        f.write(i+'\\t'+utt2spk[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2384349"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据utt2spk生成spk2utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmm/utils/utt2spk_to_spk2utt.pl data/utt2spk > data/spk2utt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/Dataset/audio_aug && bash wav_aug_common.sh --aug-list \"reverb babble volume\" --srcdir /home1/meichaoyang/workspace/git/16k_model/aishell_16k/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合增强后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in (\"utt2spk\" , \"text\"):\n",
    "    for typ in (\"reverb\",\"babble\", \"volume\"):\n",
    "        fields = [0,1]\n",
    "        if file == \"text\":\n",
    "            fields = [0]\n",
    "        copy_file_if_exists(\"data/\"+file, \"data_\"+typ+\"/\"+file, \"prefix\", typ,fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils/data/combine_data.sh ../combine_data ../data_reverb ../data_babble ../data_volume\n",
      "utils/data/combine_data.sh: combined utt2uniq\n",
      "utils/data/combine_data.sh [info]: not combining segments as it does not exist\n",
      "utils/data/combine_data.sh: combined utt2spk\n",
      "utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist\n",
      "utils/data/combine_data.sh [info]: not combining utt2dur as it does not exist\n",
      "utils/data/combine_data.sh [info]: **not combining reco2dur as it does not exist everywhere**\n",
      "utils/data/combine_data.sh [info]: not combining feats.scp as it does not exist\n",
      "utils/data/combine_data.sh: combined text\n",
      "utils/data/combine_data.sh [info]: not combining cmvn.scp as it does not exist\n",
      "utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist\n",
      "utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist\n",
      "utils/data/combine_data.sh: combined wav.scp\n",
      "utils/data/combine_data.sh [info]: not combining spk2gender as it does not exist\n",
      "- ../combine_data/utt2spk differ: char 60, line 2\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "utt2spk is not in sorted order (fix this yourself)\n"
     ]
    }
   ],
   "source": [
    "!cd gmm && bash utils/data/combine_data.sh ../combine_data ../data_reverb ../data_babble ../data_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = {}\n",
    "for file in (\"utt2spk\" , \"text\"):\n",
    "    for typ in (\"reverb\",\"babble\", \"volume\"):\n",
    "        summed = {**summed,**parse_file_to_dict(\"data_\"+typ+\"/\"+file)}\n",
    "    write_dict_to_file(summed, \"combine_data/\" +file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmm/utils/utt2spk_to_spk2utt.pl combine_data/utt2spk > combine_data/spk2utt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/\\s.*$/ 1/' gmm/data/dict/lexicon.txt > seg.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home1/meichaoyang/workspace/git/16k_model/aishell_16k/seg.dict ...\n",
      "Dumping model to file cache /home1/meichaoyang/anaconda3/lib/python3.7/site-packages/jieba/cache/jieba.u74b91bd8b6f08f8d6543d6f6267dfa9e.cache\n",
      "Loading model cost 0.432 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#!python seg_word/segmentword.py seg.dict corpus.txt corpus.seg oov_file\n",
    "\n",
    "\n",
    "vocab_file=\"seg.dict\"\n",
    "trans_file=\"combine_data/text\"\n",
    "word_segmented_trans=\"combine_data/text.seg\"\n",
    "\n",
    "jieba.set_dictionary(vocab_file)\n",
    "with open(word_segmented_trans, \"w\") as f:\n",
    "    for line in open(trans_file):\n",
    "      key,trans = line.strip().split(None, 1)\n",
    "      words = jieba.cut(trans, HMM=False) # turn off new word discovery (HMM-based)\n",
    "      new_line = key + '\\t' + \" \".join(words)\n",
    "      f.write(new_line + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spk2utt，utt2spk，text(corpus.seg)，wav.scp(wav.scp.new)复制到train_{mfcc,fbank}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf train_mfcc train_fbank\n",
    "!mkdir train_mfcc train_fbank\n",
    "!cd combine_data && cp spk2utt utt2spk text.seg wav.scp ../train_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv train_mfcc/text.seg train_mfcc/text \n",
    "#!mv train_mfcc/wav.scp.new train_mfcc/wav.scp\n",
    "!cd train_mfcc &&cp spk2utt utt2spk text wav.scp ../train_fbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征提取`cd ext_feats && sh ext_{mfcc,fbank}.sh {train_fbank,train_mfcc,dev}`，需注意修改conf下mfcc，fbank参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/make_mfcc.sh --nj 48 --cmd run.pl ../train_mfcc ../train_mfcc/log ../train_mfcc/_mfcc\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "utils/validate_data_dir.sh: utt2spk is not in sorted order when sorted first on speaker-id \n",
      "(fix this by making speaker-ids prefixes of utt-ids)\n"
     ]
    }
   ],
   "source": [
    "!cd ext_feats && sh ext_mfcc.sh ../train_mfcc && utils/fix_data_dir.sh ../train_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ext_feats && sh ext_fbank.sh ../train_fbank && utils/fix_data_dir.sh ../train_fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../../train_mfcc gmm/data/train  > /dev/null 2>&1\n",
    "!ln -s ../../train_fbank chain/data/train_fbank  > /dev/null 2>&1\n",
    "!ln -s ../../gmm/data/train/ chain/data/train_mfcc  > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd gmm && make prepare_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd gmm &&make -f Makefile gmm  | tee gmm.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chain训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1,3 && cd chain && make chain |  tee chain.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建解码图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd chain && local/make_graph.sh /home1/meichaoyang/dataset/lm/all.lm.order4.1e-9 data/lang exp/chain/tdnn_attend data/dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd chain && bash steps/nnet3/decode.sh --nj 8 exp/chain/tdnn_attend/graph /home1/meichaoyang/dataset/data_aishell2/feats/test aishell_chain_result_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chain模型再训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据chain模型生成对齐和词图（可更改chain模型下的frame采样因子来改变对齐数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/nnet3/align.sh --nj 3 --use_gpu true ../train_fbank ../gmm/data/lang exp/chain/tdnn_attend chain_align\n",
      "./steps/nnet3/align.sh: no such file exp/chain/tdnn_attend/final.mdl\n"
     ]
    }
   ],
   "source": [
    "!cd chain &&./steps/nnet3/align_lats.sh --generate-ali-from-lats true --nj 24 --scale_opts '--transition-scale=1.0 --self-loop-scale=1.0' --acoustic_scale 1.0 --generate_ali_from_lats true ../train_fbank ../gmm/data/lang exp/chain/tdnn_attend exp/chain/chain_align_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据chain模型的对齐再训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=3 &&cd chain && bash local/train_chain_again.sh --ali_dir exp/chain/chain_align_lat --alignment_subsampling_factor 1 exp/chain/tdnn_attend_again | tee chain_again.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用新的声学模型构建解码图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd chain && local/make_graph.sh /home1/meichaoyang/dataset/lm/all.lm.order4.1e-9 data/lang exp/chain/tdnn_attend_again data/dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码测试新训练的chain模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/get_train_ctm.sh data/train_fbank data/lang chain_align\r\n",
      "./steps/get_train_ctm.sh: expecting file chain_align/final.mdl to exist\r\n"
     ]
    }
   ],
   "source": [
    "!cd chain && bash steps/nnet3/decode.sh --nj 8 exp/chain/tdnn_attend_again/graph /home1/meichaoyang/dataset/data_aishell2/feats/test aishell_chain_again——result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: discount coeff 1 is out of range: 0\r\n"
     ]
    }
   ],
   "source": [
    "#!sed 's/[^\\s]*\\s//' corpus.seg > corpus_lm.txt\n",
    "!ngram-count -text corpus_lm.txt -order 1 -unk -map-unk \"<UNK>\" -interpolate -lm corpus.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd chain/ && make make_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
