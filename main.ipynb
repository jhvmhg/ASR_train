{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path_item in SLR_wav_list:\n",
    "#     wav_path = str(path_item)\n",
    "#     shutil.move(wav_path,wav_path[0:-4]) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd data && python ../tools/prep_dict.py lexicon.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./tools/prepare_dict.sh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf gmm/data/dict/\n",
    "# !mkdir gmm/data/dict/\n",
    "# !cd data &&cp lexicon.txt silence_phones.txt nonsilence_phones.txt extra_questions.txt optional_silence.txt ../gmm/data/dict\n",
    "# # !rm silence_phones.txt nonsilence_phones.txt extra_questions.txt optional_silence.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLR85生成wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLR85_dir = \"/home1/meichaoyang/Dataset/feats/SLR85/hifi\"\n",
    "SLR_wav_list=list(Path(SLR85_dir).rglob(\"*.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLR_wav_list.sort(key=lambda Path: os.path.basename(os.path.splitext((str(Path)))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2719"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SLR_wav_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SLR_wav.scp', 'w') as f:\n",
    "    for path_item in SLR_wav_list:\n",
    "        wav_path = str(path_item)\n",
    "        f.write(os.path.basename(os.path.splitext((wav_path))[0])+'\\t'+wav_path+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 并筛选一部分放入SLR_wav.scp.shuff文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bash tools/random_line.sh SLR_wav.scp 100 SLR_wav.scp.shuff\n",
    "!cat SLR_wav.scp > SLR_wav.scp.shuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 并筛选一部分放入SLR_wav.scp.shuff文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aishell2数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成Aishell2的原始wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_dir = \"/home1/meichaoyang/Dataset/data_aishell2/data_aishell/wav/train\"\n",
    "aishell_wav_list=list(Path(aishell_dir).rglob(\"*.wav\"))\n",
    "aishell_wav_list.sort(key=lambda Path: os.path.basename(os.path.splitext((str(Path)))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_scp_raw = {}\n",
    "with open('Aishell_wav_raw.scp', 'w') as f:\n",
    "    for path_item in aishell_wav_list:\n",
    "        wav_path = str(path_item)\n",
    "        aishell_scp_raw[os.path.basename(os.path.splitext((wav_path))[0])] = wav_path\n",
    "        f.write(os.path.basename(os.path.splitext((wav_path))[0])+'\\t'+wav_path+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对满足条件的标注进行筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_utt = re.compile(r'/.*\\.')\n",
    "pattern_Eng = re.compile(u'[a-zA-Z\\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_2_corp_raw = \"/home1/meichaoyang/Dataset/data_aishell2/data_aishell/wav/trans.txt\"\n",
    "corp_map = {}\n",
    "with open(aishell_2_corp_raw, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        if pattern_Eng.search(data[1]) != None: ##删除小于10和非英文标注\n",
    "            continue\n",
    "        corp_map[pattern_utt.search(data[0]).group()[1:-1]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_scp = {}\n",
    "for i in sorted(aishell_scp_raw):\n",
    "    if i not in corp_map.keys():\n",
    "        continue\n",
    "    aishell_scp[i] = aishell_scp_raw[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aishell_2.scp', 'w') as f:\n",
    "    for i in aishell_scp:\n",
    "        f.write(i+'\\t'+aishell_scp[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aishell_2_trans.txt', 'w') as f:\n",
    "    for i in corp_map:\n",
    "        f.write(i+'\\t'+corp_map[i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选一部分到aishell_2.scp.shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bash tools/random_line.sh aishell_2.scp 2 aishell_2.scp.shuff\n",
    "! cat aishell_2.scp > aishell_2.scp.shuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLR_wav_scp = {}\n",
    "SLR_wav_corp = {}\n",
    "with open(\"SLR_wav.scp.shuff\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        SLR_wav_scp[data[0]] = data[1]\n",
    "        SLR_wav_corp[data[0]] = \"NOISE你好NOISE米雅NOISE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aishell_wav_scp = {}\n",
    "with open(\"aishell_2.scp.shuff\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        aishell_wav_scp[data[0]] = data[1]\n",
    "        \n",
    "aishell_wav_corp = {}       \n",
    "with open(\"aishell_2_trans.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        if data[0] in aishell_wav_scp:\n",
    "            aishell_wav_corp[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_scp = {**SLR_wav_scp,**aishell_wav_scp}\n",
    "corpus = {**SLR_wav_corp, **aishell_wav_corp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wav.scp', 'w') as f:\n",
    "    for i in sorted(wav_scp):\n",
    "        f.write(i+'\\t'+wav_scp[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'w') as f:\n",
    "    for i in sorted(corpus):\n",
    "        f.write(i+'\\t'+corpus[i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成词典并分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/\\s.*$/ 1/' data/lexicon.txt > seg.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home1/meichaoyang/workspace/wake_up_align_44_1k/seg.dict ...\n",
      "Dumping model to file cache /home1/meichaoyang/anaconda3/lib/python3.7/site-packages/jieba/cache/jieba.u64e3cf1df5ecc565728f91fad7ae6dd0.cache\n",
      "Loading model cost 0.408 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#!python seg_word/segmentword.py seg.dict corpus.txt corpus.seg oov_file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocab_file=\"seg.dict\"\n",
    "trans_file=\"corpus.txt\"\n",
    "word_segmented_trans=\"corpus.seg\"\n",
    "\n",
    "jieba.set_dictionary(vocab_file)\n",
    "with open(word_segmented_trans, \"w\") as f:\n",
    "    for line in open(trans_file):\n",
    "      key,trans = line.strip().split(None, 1)\n",
    "      words = jieba.cut(trans, HMM=False) # turn off new word discovery (HMM-based)\n",
    "      new_line = key + '\\t' + \" \".join(words)\n",
    "      f.write(new_line + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python tools/filter_scp.py corpus.seg wav.scp wav.scp.new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utt2spk和spk2utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wav_scp_path = \"wav.scp\"\n",
    "new_wav_scp = {}\n",
    "with open(new_wav_scp_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        new_wav_scp[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SV0255'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(u'/[^/]+')\n",
    "str1 = '/home/meichaoyang/dataset/SLR85/dev/SPEECHDATA/wav/SV0255/SV0255_2_00_F0026.wav'\n",
    "pattern.findall(str1)[-2][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895986"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_wav_scp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "utts = list(new_wav_scp.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt2spk = {}\n",
    "for utt in utts:\n",
    "    spk = pattern.findall(utt[1])[-2][1:]\n",
    "    utt2spk[utt[0]] = spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk2utt = {}\n",
    "for utt in utts:\n",
    "    spk = pattern.findall(utt[1])[-2][1:]\n",
    "    if spk not in spk2utt:\n",
    "        spk2utt[spk] = []\n",
    "    spk2utt[spk].append(utt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utt2spk', 'w') as f:\n",
    "    for i in sorted(utt2spk):\n",
    "        f.write(i+'\\t'+utt2spk[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895986"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据utt2spk生成spk2utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmm/utils/utt2spk_to_spk2utt.pl utt2spk > spk2utt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spk2utt，utt2spk，text(corpus.seg)，wav.scp(wav.scp.new)复制到train_{mfcc,fbank}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf train_mfcc train_fbank\n",
    "!mkdir train_mfcc train_fbank\n",
    "!cp spk2utt utt2spk corpus.seg wav.scp train_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv train_mfcc/corpus.seg train_mfcc/text \n",
    "#!mv train_mfcc/wav.scp.new train_mfcc/wav.scp\n",
    "!cd train_mfcc &&cp spk2utt utt2spk text wav.scp ../train_fbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征提取`cd ext_feats && sh ext_{mfcc,fbank}.sh {train_fbank,train_mfcc,dev}`，需注意修改conf下mfcc，fbank参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/make_mfcc.sh --nj 48 --cmd run.pl ../train_mfcc ../train_mfcc/log ../train_mfcc/_mfcc\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ../train_mfcc\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "Succeeded creating MFCC features for train_mfcc\n",
      "steps/compute_cmvn_stats.sh ../train_mfcc ../train_mfcc/cmvn_log ../train_mfcc/_cmvn\n",
      "Succeeded creating CMVN stats for train_mfcc\n",
      "fix_data_dir.sh: kept all 895986 utterances.\n",
      "fix_data_dir.sh: old files are kept in ../train_mfcc/.backup\n"
     ]
    }
   ],
   "source": [
    "!cd ext_feats && sh ext_mfcc.sh ../train_mfcc && utils/fix_data_dir.sh ../train_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/make_fbank.sh --nj 48 --cmd run.pl ../train_fbank ../train_fbank/log ../train_fbank/_fbank\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ../train_fbank\n",
      "steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "Succeeded creating filterbank features for train_fbank\n",
      "steps/compute_cmvn_stats.sh ../train_fbank ../train_fbank/cmvn_log ../train_fbank/_cmvn\n",
      "Succeeded creating CMVN stats for train_fbank\n",
      "fix_data_dir.sh: kept all 895986 utterances.\n",
      "fix_data_dir.sh: old files are kept in ../train_fbank/.backup\n"
     ]
    }
   ],
   "source": [
    "!cd ext_feats && sh ext_fbank.sh ../train_fbank && utils/fix_data_dir.sh ../train_fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../../train_mfcc gmm/data/train\n",
    "!ln -s ../../train_fbank chain/data/train_fbank\n",
    "!ln -s ../../gmm/data/train/ chain/data/train_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils/prepare_lang.sh --position-dependent-phones false `pwd`/data/dict \"SPOKEN_NOISE\" `pwd`/data/local/lang `pwd`/data/lang\n",
      "utils/prepare_lang.sh --position-dependent-phones false /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict SPOKEN_NOISE /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/local/lang /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/silence_phones.txt ...\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/silence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/silence_phones.txt is OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/optional_silence.txt ...\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/optional_silence.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/optional_silence.txt is OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/nonsilence_phones.txt ...\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/nonsilence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/nonsilence_phones.txt is OK\n",
      "\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\n",
      "--> disjoint property is OK.\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexicon.txt\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexicon.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexicon.txt is OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexiconp.txt\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexiconp.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexiconp.txt is OK\n",
      "\n",
      "Checking lexicon pair /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexicon.txt and /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexiconp.txt\n",
      "--> lexicon pair /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexicon.txt and /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/lexiconp.txt match\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/extra_questions.txt ...\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/extra_questions.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict/extra_questions.txt is OK\n",
      "--> SUCCESS [validating dictionary directory /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/dict]\n",
      "\n",
      "fstaddselfloops /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/wdisambig_phones.int /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/wdisambig_words.int \n",
      "prepare_lang.sh: validating output directory\n",
      "utils/validate_lang.pl /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 3 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.csl corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 217 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.csl corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 3 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.csl corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.csl corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 57 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.csl corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 69 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/roots.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/roots.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/roots.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 69 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/sets.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/sets.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/sets.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 7 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/extra_questions.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/extra_questions.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/extra_questions.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/oov.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/oov.int corresponds to /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/oov.txt\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/oov.{txt, int} are OK\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/L.fst is olabel sorted\n",
      "--> /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang/L_disambig.fst is olabel sorted\n",
      "--> SUCCESS [validating lang directory /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/lang]\n"
     ]
    }
   ],
   "source": [
    "!cd gmm && make prepare_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local/train_gmm.sh `pwd`/data/train `pwd`/data/cv\n",
      "steps/train_mono.sh --boost-silence 1.25 --nj 24 --cmd run.pl /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/mono\n",
      "steps/train_mono.sh: Initializing monophone system.\n",
      "steps/train_mono.sh: Compiling training graphs\n",
      "steps/train_mono.sh: Aligning data equally (pass 0)\n",
      "steps/train_mono.sh: Pass 1\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 2\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 3\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 4\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 5\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 6\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 7\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 8\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 9\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 10\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 11\n",
      "steps/train_mono.sh: Pass 12\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 13\n",
      "steps/train_mono.sh: Pass 14\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 15\n",
      "steps/train_mono.sh: Pass 16\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 17\n",
      "steps/train_mono.sh: Pass 18\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 19\n",
      "steps/train_mono.sh: Pass 20\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 21\n",
      "steps/train_mono.sh: Pass 22\n",
      "steps/train_mono.sh: Pass 23\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 24\n",
      "steps/train_mono.sh: Pass 25\n",
      "steps/train_mono.sh: Pass 26\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 27\n",
      "steps/train_mono.sh: Pass 28\n",
      "steps/train_mono.sh: Pass 29\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 30\n",
      "steps/train_mono.sh: Pass 31\n",
      "steps/train_mono.sh: Pass 32\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 33\n",
      "steps/train_mono.sh: Pass 34\n",
      "steps/train_mono.sh: Pass 35\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 36\n",
      "steps/train_mono.sh: Pass 37\n",
      "steps/train_mono.sh: Pass 38\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 39\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/mono\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log\n",
      "15740 warnings in exp/mono/log/acc.*.*.log\n",
      "93874 warnings in exp/mono/log/align.*.*.log\n",
      "6 warnings in exp/mono/log/init.log\n",
      "exp/mono: nj=24 align prob=-93.57 over 870.96h [retry=0.2%, fail=0.1%] states=213 gauss=995\n",
      "steps/train_mono.sh: Done training monophone system in exp/mono\n",
      "steps/align_si.sh --boost-silence 1.25 --nj 24 --cmd run.pl /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/mono exp/mono_ali\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train using model from exp/mono, putting alignments in exp/mono_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/mono_ali\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl 10000 80000 /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/mono_ali exp/tri1\n",
      "steps/train_deltas.sh: accumulating tree stats\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\n",
      "steps/train_deltas.sh: building the tree\n",
      "steps/train_deltas.sh: converting alignments from exp/mono_ali to use current tree\n",
      "steps/train_deltas.sh: compiling graphs of transcripts\n",
      "steps/train_deltas.sh: training pass 1\n",
      "steps/train_deltas.sh: training pass 2\n",
      "steps/train_deltas.sh: training pass 3\n",
      "steps/train_deltas.sh: training pass 4\n",
      "steps/train_deltas.sh: training pass 5\n",
      "steps/train_deltas.sh: training pass 6\n",
      "steps/train_deltas.sh: training pass 7\n",
      "steps/train_deltas.sh: training pass 8\n",
      "steps/train_deltas.sh: training pass 9\n",
      "steps/train_deltas.sh: training pass 10\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 11\n",
      "steps/train_deltas.sh: training pass 12\n",
      "steps/train_deltas.sh: training pass 13\n",
      "steps/train_deltas.sh: training pass 14\n",
      "steps/train_deltas.sh: training pass 15\n",
      "steps/train_deltas.sh: training pass 16\n",
      "steps/train_deltas.sh: training pass 17\n",
      "steps/train_deltas.sh: training pass 18\n",
      "steps/train_deltas.sh: training pass 19\n",
      "steps/train_deltas.sh: training pass 20\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 21\n",
      "steps/train_deltas.sh: training pass 22\n",
      "steps/train_deltas.sh: training pass 23\n",
      "steps/train_deltas.sh: training pass 24\n",
      "steps/train_deltas.sh: training pass 25\n",
      "steps/train_deltas.sh: training pass 26\n",
      "steps/train_deltas.sh: training pass 27\n",
      "steps/train_deltas.sh: training pass 28\n",
      "steps/train_deltas.sh: training pass 29\n",
      "steps/train_deltas.sh: training pass 30\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 31\n",
      "steps/train_deltas.sh: training pass 32\n",
      "steps/train_deltas.sh: training pass 33\n",
      "steps/train_deltas.sh: training pass 34\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri1\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log\n",
      "25242 warnings in exp/tri1/log/acc.*.*.log\n",
      "1 warnings in exp/tri1/log/build_tree.log\n",
      "12221 warnings in exp/tri1/log/align.*.*.log\n",
      "exp/tri1: nj=24 align prob=-91.19 over 870.41h [retry=0.4%, fail=0.1%] states=7872 gauss=80228 tree-impr=4.25\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1\n",
      "steps/align_si.sh --nj 24 --cmd run.pl /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/tri1 exp/tri1_ali\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train using model from exp/tri1, putting alignments in exp/tri1_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri1_ali\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/train_lda_mllt.sh --cmd run.pl --splice-opts --left-context=3 --right-context=3 12000 120000 /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/tri1_ali exp/tri2b\n",
      "steps/train_lda_mllt.sh: Accumulating LDA statistics.\n",
      "steps/train_lda_mllt.sh: Accumulating tree stats\n",
      "steps/train_lda_mllt.sh: Getting questions for tree clustering.\n",
      "steps/train_lda_mllt.sh: Building the tree\n",
      "steps/train_lda_mllt.sh: Initializing the model\n",
      "steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali to use current tree\n",
      "steps/train_lda_mllt.sh: Compiling graphs of transcripts\n",
      "Training pass 1\n",
      "Training pass 2\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\n",
      "Training pass 3\n",
      "Training pass 4\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\n",
      "Training pass 5\n",
      "Training pass 6\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\n",
      "Training pass 7\n",
      "Training pass 8\n",
      "Training pass 9\n",
      "Training pass 10\n",
      "Aligning data\n",
      "Training pass 11\n",
      "Training pass 12\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\n",
      "Training pass 13\n",
      "Training pass 14\n",
      "Training pass 15\n",
      "Training pass 16\n",
      "Training pass 17\n",
      "Training pass 18\n",
      "Training pass 19\n",
      "Training pass 20\n",
      "Aligning data\n",
      "Training pass 21\n",
      "Training pass 22\n",
      "Training pass 23\n",
      "Training pass 24\n",
      "Training pass 25\n",
      "Training pass 26\n",
      "Training pass 27\n",
      "Training pass 28\n",
      "Training pass 29\n",
      "Training pass 30\n",
      "Aligning data\n",
      "Training pass 31\n",
      "Training pass 32\n",
      "Training pass 33\n",
      "Training pass 34\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri2b\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log\n",
      "940 warnings in exp/tri2b/log/lda_acc.*.log\n",
      "1 warnings in exp/tri2b/log/compile_questions.log\n",
      "34015 warnings in exp/tri2b/log/acc.*.*.log\n",
      "15334 warnings in exp/tri2b/log/align.*.*.log\n",
      "1 warnings in exp/tri2b/log/build_tree.log\n",
      "1 warnings in exp/tri2b/log/questions.log\n",
      "exp/tri2b: nj=24 align prob=-48.13 over 870.23h [retry=0.4%, fail=0.1%] states=9392 gauss=120252 tree-impr=4.62 lda-sum=21.13 mllt:impr,logdet=0.93,1.43\n",
      "steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/align_si.sh --nj 24 --cmd run.pl --use-graphs true /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/tri2b exp/tri2b_ali\n",
      "steps/align_si.sh: feature type is lda\n",
      "steps/align_si.sh: aligning data in /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri2b_ali\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/train_sat.sh --cmd run.pl 15000 180000 /home1/meichaoyang/workspace/wake_up_align_44_1k/gmm/data/train data/lang exp/tri2b_ali exp/tri3b\n",
      "steps/train_sat.sh: feature type is lda\n",
      "steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali\n",
      "steps/train_sat.sh: Accumulating tree stats\n",
      "steps/train_sat.sh: Getting questions for tree clustering.\n",
      "steps/train_sat.sh: Building the tree\n",
      "steps/train_sat.sh: Initializing the model\n",
      "steps/train_sat.sh: Converting alignments from exp/tri2b_ali to use current tree\n",
      "steps/train_sat.sh: Compiling graphs of transcripts\n",
      "Pass 1\n",
      "Pass 2\n",
      "Estimating fMLLR transforms\n",
      "Pass 3\n",
      "Pass 4\n",
      "Estimating fMLLR transforms\n",
      "Pass 5\n",
      "Pass 6\n",
      "Estimating fMLLR transforms\n",
      "Pass 7\n",
      "Pass 8\n",
      "Pass 9\n",
      "Pass 10\n",
      "Aligning data\n",
      "Pass 11\n",
      "Pass 12\n",
      "Estimating fMLLR transforms\n",
      "Pass 13\n",
      "Pass 14\n",
      "Pass 15\n",
      "Pass 16\n",
      "Pass 17\n",
      "Pass 18\n",
      "Pass 19\n",
      "Pass 20\n",
      "Aligning data\n",
      "Pass 21\n",
      "Pass 22\n",
      "Pass 23\n",
      "Pass 24\n",
      "Pass 25\n",
      "Pass 26\n",
      "Pass 27\n",
      "Pass 28\n",
      "Pass 29\n",
      "Pass 30\n",
      "Aligning data\n"
     ]
    }
   ],
   "source": [
    "!cd gmm &&make -f Makefile gmm  | tee gmm.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1,2 && cd chain && make chain |  tee chain.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: discount coeff 1 is out of range: 0\r\n"
     ]
    }
   ],
   "source": [
    "#!sed 's/[^\\s]*\\s//' corpus.seg > corpus_lm.txt\n",
    "!ngram-count -text corpus_lm.txt -order 1 -unk -map-unk \"<UNK>\" -interpolate -lm corpus.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local/make_graph.sh /home1/meichaoyang/Workspace/wake_up/corpus.lm `pwd`/data/lang exp/chain/tdnn_attend `pwd`/data/dict\r\n",
      "gzip: /home1/meichaoyang/Workspace/wake_up/corpus.lm: No such file or directory\r\n",
      "Makefile:18: recipe for target 'make_graph' failed\r\n",
      "make: *** [make_graph] Error 1\r\n"
     ]
    }
   ],
   "source": [
    "!cd chain/ && make make_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'asdf']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"asdf asdf\".split(' ', 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23G\tchain/exp\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh chain/exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
